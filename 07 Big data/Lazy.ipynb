{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "Requires **HyperSpy 1.4.2 or above**\n",
    "\n",
    "This tutorial introduces to the processing of large dataset - which can not fit into memory - using HyperSpy. It introduce the concept of out-of-core computation algorithms (also refer as lazy processing) and the main difference between lazy and non-lazy processing as well as technicallities you need to be aware of to optimise performance.\n",
    "The corresponding section of the HyperSpy documentation is [the big data section](https://hyperspy.readthedocs.io/en/stable/user_guide/big_data.html#limitations).\n",
    "\n",
    "### Credits and changes\n",
    "\n",
    "* 29/07/2021 Eric Prestat. Update for the M&M Sunday short course.\n",
    "* 29/07/2019 Eric Prestat. Add more details and introduction for the M&M Sunday short course.\n",
    "* 15/03/2019 Francisco de la Pe√±a. Create tutorial for the HyperSpy workshop at ePSIC.\n",
    "\n",
    "## Table of contents\n",
    "1. [Introduction to lazy processing](#1.-Introduction-to-lazy-processing)\n",
    "2. [Loading data lazily](#2.-Loading-data-lazily)\n",
    "3. [Plotting lazily](#3.-Plotting-lazily)\n",
    "4. [Rebinning](#4.-Rebinning)\n",
    "5. [Rebinning](#5.-Rebinning)\n",
    "6. [ROI in navigation dimension](#6.-ROI-in-navigation-dimension)\n",
    "7. [Summary](#7.-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to lazy processing\n",
    "\n",
    "Lazy processing refers to the use of [out-of-core computation algorithms](https://en.wikipedia.org/wiki/External_memory_algorithm) to process very large data, which are usually too large to fit into the computer's memory at one time. The main idea is to chunk the data in pieces, small enough, that can be processed in memory as illustrated by the following diagram:\n",
    "\n",
    "<img src=\"lazy/out-of-core_diagram.svg\" width=\"500\">\n",
    "\n",
    "HyperSpy internally uses the [dask library](https://docs.dask.org/en/latest/index.html), which implements the numpy interface to larger-than-memory or distributed environments. The typically workflow for processing data lazily is available on a disk:\n",
    " 1. \"load\" data from disk with a defined chunking\n",
    " 2. schedule operations\n",
    " 3. do the computation\n",
    "\n",
    "**Steps 1 and 2 are very fast**, because nothing is actually done, other than initialising and scheduling the tasks to be peformed.\n",
    "**Step 3 is slow**, because all the computation is performed at this stage. Most of the time, this is signficantly slower than in memory processing, because the chunks of data needs to be read and written from/to disk when on request of the scheduler.\n",
    "\n",
    "The following diagram shows a task graph, where square and rounds represent arrays and functions, respectively. This graph is an example of how dask is going process the data from the large data set on the harddrive (HDD) into chunks and do computation on these.\n",
    "\n",
    "This example below a simple example shows of how to perform out-of-core computation using dask, here the calculation of the sum of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "# Create a 15x15 array filled with ones and chunks size to 5x5\n",
    "x = da.ones((15, 15), chunks=(5, 5))\n",
    "\n",
    "# Take the sum()\n",
    "y = x.sum()\n",
    "\n",
    "# do the computation\n",
    "y.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding tasks can be representated by the following graph (square are array):\n",
    " - square are arrays, which can fit into memory\n",
    " - circle are operations\n",
    " \n",
    "<img src=\"lazy/sum.svg\" width=\"500\">\n",
    "\n",
    "Read [the graph](https://docs.dask.org/en/latest/graphs.html) section of the dask documenation for more explanation. The taks graph can be visualised using the [visualise](https://docs.dask.org/en/latest/graphviz.html) method.\n",
    "\n",
    "For a short ontroductory presentation on dask and its principle see http://matthewrocklin.com/slides/plotcon-2016.html. The following animation - taken from the previously mentioned presentation - illustrates the execution of the scheduled computation of many tasks:\n",
    "\n",
    "![Dask's directed acyclic diagram (DAG)](lazy/grid_search_schedule.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of out-of-core computation in HyperSpy aims to make processing very large data (not fitting into memory) as seamlessly as possible and similar to in-memory data. This tutorial covers the main difference between lazy and non-lazy processing as well as technicallities you need to be aware of to optimise performance.\n",
    "\n",
    "## 2. Loading data lazily\n",
    "\n",
    "As usual, we start by setting up the matplotlib backend and importing hyperspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by setting the ``logging level`` to \"INFO\" using the preferences GUI as below. Once done, click ``Save`` and restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the preferences GUI and set the logging level to INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we are going to start by loading a large spectrum image lazily  that won't fit into the 2GB of memory available on binder, so notice the ``lazy`` keyword and don't forget to set it to ``True``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open lazily the file \"synthetic_dataset.hspy\" in the subfolder \"lazy\":\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what sort of object we have stored in the ``s`` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a spectrum image with *4096* spectral channels and *512x512* image dimensions. Its size in GB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"nbytes\" attribute of the dask array to calculate the size on disk\n",
    "s.data.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about *2 GB* of data. However, loading it tooks no time. That's because HyperSpy didn't load the data yet. It'll do it on demand.\n",
    "\n",
    "## 3. Plotting lazily \n",
    "\n",
    "Let's plot the spectrum image. Usually we would call simply:\n",
    "\n",
    "```python\n",
    "s.plot()\n",
    "```\n",
    "\n",
    "And a navigator would appear. The navigator is the sum over the signal dimension and in case of large data, computing the navigator can be too long, because it means that we will need to go through the whole dataset.\n",
    "\n",
    "For lazy signal, the navigator is computed slightly differently: the navigator is computed using a single chunk in the signal dimension. If the chunking is appropriate, it can be fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot `s`\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time, `plot` is called, the navigator is computed and saved in the `navigator` attribute. In this case, this was quite fast, because this signal has 5 chunks in the signal dimension and we used only a small portion of the whole dataset to compute the navigator.\n",
    "\n",
    "Let's have a look at the data chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compute the navigator yourself and saved it to the `navigator` attribute or use the convenience method compute_navigator `compute_navigator`, for example by looking at specimen energy position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.compute_navigator(index=6.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compute_navigator` takes the sum over whole chunks to increase signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.navigator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = hs.load('synthetic_dataset_chunking.hspy', lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the signal dimension contains a single chunk. This makes plotting faster, because it avoids retrieve several chunks for the selected navigation position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EDS mapping\n",
    "Lazy processing will follow the same syntax as for the non-lazy signal, expect that the `compute` will need to called.\n",
    "\n",
    "Check the metadata to know if some element are already defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract X-ray line intensities as we would with non-lazy signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `get_lines_intensity` method to get the intensities of `Fe_Ka` and `Pt_La`\n",
    "intensities = s.get_lines_intensity(['Fe_Ka', 'Pt_La'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intensity in intensities:\n",
    "    intensity.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the intensity map using `hs.plot.plot_images`\n",
    "hs.plot.plot_images(intensities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Rebinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = hs.load('synthetic_dataset_chunking.hspy', lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have significantly less chunks: 64 (4096/64) chunks instead of 4096 and there are all of egal size (64, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use isig syntax to slice take the signal up to 15 eV and\n",
    "# rebin the navigation dimention by a factor of 4 using the `rebin` method\n",
    "s_rebin = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call `compute` to perform the computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rebin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`s_rebin` is not a lazy signal anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result, which have been computed and is now in memory\n",
    "s_rebin.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ROI in navigation dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot `s`\n",
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a rectagular ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RectangularROI defined by the position (left=100, top=100, right=110, bottom=110)\n",
    "s_roi = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ROI\n",
    "print(s_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling this object extracts a rectangular roi from a HyperSpy signal. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ROI from a signal:\n",
    "print(s_roi(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change its parameters interactively displaying the associated widget as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the `gui` method of the ROI to display the widget:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the changes in the roi:\n",
    "print(s_roi(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also by adding a widget to the navigator plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ROI to the signal using the `add_widget` method of the roi:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have to execute manually the ROI on the spectrum image every time that we change its parameters. We can perform this operation automatically instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `hs.interactive` function to automatically calculate a new signal from `s` and defined by the ROI:\n",
    "s2 = hs.interactive(s_roi, signal=s,\n",
    "                    event=s_roi.events.changed,\n",
    "                    recompute_out_event=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information about `s2`:\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ``interactive`` function to compute the sum of the extracted spectrum image interactively as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `hs.interactive` function to automatically calculate the sum of `s2`:\n",
    "s2_sum = hs.interactive(s2.sum,\n",
    "                        event=s2.events.data_changed,\n",
    "                        recompute_out_event=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the information of `s2_sum`:\n",
    "s2_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot it. Notice that the spectrum should update when we change the ROI parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_sum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "Most operations can be performed *lazily* in HyperSpy:\n",
    "1. Visualisation\n",
    "2. Slicing and indexing\n",
    "3. Generic mathematical operations\n",
    "4. Machine learning\n",
    "5. Curve fitting\n",
    "\n",
    "See [the big data section](https://hyperspy.readthedocs.io/en/stable/user_guide/big_data.html#limitations) of the HyperSpy documentation for more information and to learn about the main difference between lazy and non-lazy signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
